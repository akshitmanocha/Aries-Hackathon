{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after cleaning: 10688\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "    Returns:\n",
    "        str: Extracted text from the PDF\n",
    "    \"\"\"\n",
    "    extracted_text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                extracted_text += page_text + \"\\n\\n\"\n",
    "    return extracted_text.strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the text by removing numbers, special characters, and extra spaces.\n",
    "    Args:\n",
    "        text (str): Text to clean\n",
    "    Returns:\n",
    "        str: Cleaned text\n",
    "    \"\"\"\n",
    "    text_without_numbers = re.sub(r'\\d+', '', text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', ' ', text_without_numbers)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Count the number of words in the given text.\n",
    "    Args:\n",
    "        text (str): Text to count words in\n",
    "    Returns:\n",
    "        int: Number of words\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file_path = \"AriesDataset/Papers/P002.pdf\"\n",
    "    \n",
    "    full_text = extract_text_from_pdf(pdf_file_path)\n",
    "    \n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(full_text)\n",
    "    \n",
    "    # Count the words in the cleaned text\n",
    "    word_count = count_words(cleaned_text)\n",
    "    \n",
    "    print(f\"Total words after cleaning: {word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"In assessing outputs, look for evidence of originality, significance and rigour and apply the\n",
    "generic definitions of the starred quality levels as follows:\n",
    "In assessing work as being 4* (quality that is world-leading in terms of originality, significance\n",
    "and rigour), expect to see evidence of, or potential for, some of the following types of characteristics\n",
    "across and possibly beyond its area/field:\n",
    "a primary or essential point of reference;\n",
    "of profound influence;\n",
    "instrumental in developing new thinking, practices, paradigms, policies or audiences;\n",
    "a major expansion of the range and the depth of research and its application;\n",
    "outstandingly novel, innovative and/or creative.\n",
    "In assessing work as being 3* (quality that is internationally excellent in terms of originality,\n",
    "LLM's effectiveness with different settings and inputs significance and rigour but which falls short of the highest standards of excellence), expect to see\n",
    "evidence of, or potential for, some of the following types of characteristics across and possibly\n",
    "beyond its area/field:\n",
    "an important point of reference;\n",
    "of considerable influence;\n",
    "a catalyst for, or important contribution to, new thinking, practices, paradigms, policies or\n",
    "audiences;\n",
    "a significant expansion of the range and the depth of research and its application;\n",
    "significantly novel or innovative or creative.\n",
    "In assessing work as being 2* (quality that is recognised internationally in terms of originality,\n",
    "significance and rigour), expect to see evidence of, or potential for, some of the following types of\n",
    "characteristics across and possibly beyond its area/field:\n",
    "a recognised point of reference;\n",
    "of some influence;\n",
    "an incremental and cumulative advance on thinking, practices, paradigms, policies or audiences;\n",
    "a useful contribution to the range or depth of research and its application.\n",
    "In assessing work as being 1* (quality that is recognised nationally in terms of originality,\n",
    "significance and rigour), expect to see evidence of the following characteristics within its area/\n",
    "field:\n",
    "an identifiable contribution to understanding without advancing existing paradigms of enquiry\n",
    "or practice;\n",
    "of minor influence.\n",
    "Now if the score is 1 or 2 say unpublishable and if the score if 3 or 4 say that it is publishable along with a 50 word explaination\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting up API key\n",
    "from google import genai\n",
    "from mistralai import Mistral\n",
    "import cohere\n",
    "import os\n",
    "\n",
    "gemini_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "mistral_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "cohere_key = os.environ.get(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google import genai\n",
    "\n",
    "# client = genai.Client(api_key=gemini_key)\n",
    "\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     contents=f'\"{prompt}\"\\n\\n{cleaned_text} Now tell me if the paper is publishable or not and give a 50 word explanation',\n",
    "# )\n",
    "\n",
    "# print(response.text)\n",
    "\n",
    "# import os\n",
    "# from mistralai import Mistral\n",
    "\n",
    "# model = \"mistral-large-latest\"\n",
    "\n",
    "# client = Mistral(api_key=mistral_key)\n",
    "\n",
    "# chat_response = client.chat.complete(\n",
    "#     model= model,\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"What is the best French cheese?\",\n",
    "#         },\n",
    "#     ]\n",
    "# )\n",
    "# print(chat_response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# import cohere\n",
    "\n",
    "# co = cohere.ClientV2(api_key=cohere_key)\n",
    "\n",
    "# res = co.chat(\n",
    "#     model=\"command-a-03-2025\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Write a title for a blog post about API design. Only output the title text.\",\n",
    "#         }\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# print(res.message.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gemini(pdf):\n",
    "    data = extract_text_from_pdf(pdf)\n",
    "    data = clean_text(data)\n",
    "    client = genai.Client(api_key=gemini_key)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=f'\"{prompt}\"\\n\\n{data} give one word \"Publishable\" if you think this paper is publishable and \"Unpublishable\" if you think this paper is unpublishable and give a 100 word explanation why',\n",
    "    )\n",
    "    first_word = response.text.split()[0]\n",
    "    rest = ' '.join(response.text.split()[1:])\n",
    "    \n",
    "    return first_word, rest\n",
    "\n",
    "def check_mistral(pdf):\n",
    "    data = extract_text_from_pdf(pdf)\n",
    "    data = clean_text(data)\n",
    "    model = \"mistral-large-latest\"\n",
    "    client = Mistral(api_key=mistral_key)\n",
    "    \n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'{data}\\n\\nGive one word \"Publishable\" if you think this paper is publishable and \"Unpublishable\" if you think this paper is unpublishable, and give a 100-word explanation why.',\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    chat = chat_response.choices[0].message.content.strip()\n",
    "    words = chat.split()\n",
    "    first_word = words[0]\n",
    "    rest = ' '.join(words[1:])\n",
    "    return first_word, rest\n",
    "\n",
    "def check_cohere(pdf):\n",
    "    data = extract_text_from_pdf(pdf)\n",
    "    data = clean_text(data)\n",
    "    co = cohere.ClientV2(api_key=cohere_key)\n",
    "    res = co.chat(\n",
    "        model=\"command-a-03-2025\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'{data}\\n\\nGive one word \"Publishable\" if you think this paper is publishable and \"Unpublishable\" if you think this paper is unpublishable, and give a 100-word explanation why.',\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    chat = res.message.content[0].text.strip()\n",
    "    first_word = chat.split()[0]\n",
    "    rest = ' '.join(chat.split()[1:])\n",
    "    return first_word, rest\n",
    "\n",
    "def final_check(string,para1,para2,para3):\n",
    "    client = genai.Client(api_key=gemini_key)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=f'Using the following points\\n \\n{para1}\\n{para2}\\n{para3}\\n explain why the given the paper is {string} in 100 words',\n",
    "    )\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Unpublishable',\n",
       " 'This paper is unpublishable due to its lack of scientific rigor and coherence. While it uses complex terminology, the connections drawn between various concepts (photosynthesis, quantum mechanics, culinary arts, etc.) are arbitrary and nonsensical. The methodology and results sections describe experiments that are fantastical and lack any grounding in reality. The overall paper reads as a parody of scientific writing rather than a serious investigation, failing to provide any meaningful contribution to the field of photosynthesis or any other area of study.')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_gemini(\"AriesDataset/Reference/Non-Publishable/R002.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Unpublishable.',\n",
       " 'This paper is a surreal and humorous pastiche of scientific jargon and absurd hypotheses, mixing real scientific concepts with completely fabricated and nonsensical ideas. It lacks coherence, logical structure, and any semblance of serious academic inquiry. The inclusion of whimsical elements like \"quokkas,\" \"velociraptor shaped cookies,\" and \"flumplenook theory\" makes it clear that the paper is not intended to be a genuine contribution to scientific literature. It reads more like a piece of comedic fiction than a scholarly article.')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mistral(\"AriesDataset/Reference/Non-Publishable/R002.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Unpublishable.',\n",
       " \"This paper is unpublishable due to its incoherent structure, nonsensical content, and lack of scientific rigor. It presents a convoluted narrative that jumps between unrelated topics, including photosynthesis, quantum mechanics, culinary arts, and interdimensional communication, without any logical connection or meaningful analysis. The text is filled with absurd claims, fabricated methodologies, and irrelevant references, making it impossible to discern any credible scientific contribution. The use of humor and absurdity, while creative, undermines the paper's credibility and does not align with the standards of academic publishing. It lacks a clear hypothesis, methodology, results, and conclusion, rendering it unsuitable for publication in any reputable scientific journal.\")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_cohere(\"AriesDataset/Reference/Non-Publishable/R002.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AriesDataset/Reference/Non-Publishable/R001.pdf\n",
      "AriesDataset/Reference/Non-Publishable/R003.pdf\n",
      "AriesDataset/Reference/Non-Publishable/R002.pdf\n",
      "AriesDataset/Reference/Non-Publishable/R005.pdf\n",
      "AriesDataset/Reference/Non-Publishable/R004.pdf\n",
      "AriesDataset/Reference/Publishable/R014.pdf\n",
      "AriesDataset/Reference/Publishable/R015.pdf\n",
      "AriesDataset/Reference/Publishable/R012.pdf\n",
      "AriesDataset/Reference/Publishable/R006.pdf\n",
      "AriesDataset/Reference/Publishable/R007.pdf\n",
      "AriesDataset/Reference/Publishable/R013.pdf\n",
      "AriesDataset/Reference/Publishable/R011.pdf\n",
      "AriesDataset/Reference/Publishable/R010.pdf\n",
      "AriesDataset/Reference/Publishable/R009.pdf\n",
      "AriesDataset/Reference/Publishable/R008.pdf\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "False_Positives = 0\n",
    "False_Negatives = 0\n",
    "True_Positives = 0\n",
    "True_Negatives = 0\n",
    "\n",
    "def run_ensemble():\n",
    "    global False_Positives, False_Negatives, True_Positives, True_Negatives\n",
    "\n",
    "    for docs in os.listdir(\"AriesDataset/Reference/Non-Publishable\"):\n",
    "        pdf = os.path.join(\"AriesDataset/Reference/Non-Publishable\", docs)\n",
    "        print(pdf)\n",
    "        first_word_gem, rest_gem = check_gemini(pdf)\n",
    "        first_word_mis, rest_mis = check_mistral(pdf)\n",
    "        first_word_coh, rest_coh = check_cohere(pdf)\n",
    "\n",
    "        unpublishable_count = 0\n",
    "        if first_word_gem[0] == \"U\":\n",
    "            unpublishable_count += 1\n",
    "        if first_word_mis[0] == \"U\":\n",
    "            unpublishable_count += 1\n",
    "        if first_word_coh[0] == \"U\":\n",
    "            unpublishable_count += 1\n",
    "        \n",
    "        if unpublishable_count >= 2:\n",
    "            True_Negatives += 1\n",
    "        else:\n",
    "            False_Positives += 1\n",
    "\n",
    "    for docs in os.listdir(\"AriesDataset/Reference/Publishable\"):\n",
    "        pdf = os.path.join(\"AriesDataset/Reference/Publishable\", docs)\n",
    "        print(pdf)\n",
    "        first_word_gem, rest_gem = check_gemini(pdf)\n",
    "        first_word_mis, rest_mis = check_mistral(pdf)\n",
    "        first_word_coh, rest_coh = check_cohere(pdf)\n",
    "\n",
    "        publishable_count = 0\n",
    "        if first_word_gem[0] == \"P\":\n",
    "            publishable_count += 1\n",
    "        if first_word_mis[0] == \"P\":\n",
    "            publishable_count += 1\n",
    "        if first_word_coh[0] == \"P\":\n",
    "            publishable_count += 1\n",
    "        \n",
    "        if publishable_count >= 2:\n",
    "            True_Positives += 1\n",
    "        else:\n",
    "            False_Negatives += 1\n",
    "\n",
    "run_ensemble()\n",
    "\n",
    "# Metrics\n",
    "precision = True_Positives / (True_Positives + False_Positives) if (True_Positives + False_Positives) > 0 else 0\n",
    "recall = True_Positives / (True_Positives + False_Negatives) if (True_Positives + False_Negatives) > 0 else 0\n",
    "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pdf):\n",
    "    print(pdf)\n",
    "    first_word_gem, rest_gem = check_gemini(pdf)\n",
    "    first_word_mis, rest_mis = check_mistral(pdf)\n",
    "    first_word_coh, rest_coh = check_cohere(pdf)\n",
    "\n",
    "    publishable_count = 0\n",
    "    string = \"Unpublishable\"\n",
    "    if first_word_gem[0] == \"P\":\n",
    "        publishable_count += 1\n",
    "    if first_word_mis[0] == \"P\":\n",
    "        publishable_count += 1\n",
    "    if first_word_coh[0] == \"P\":\n",
    "        publishable_count += 1\n",
    "\n",
    "    if publishable_count>=2:\n",
    "        string = \"Publishable\"\n",
    "\n",
    "    para = final_check(string,rest_gem, rest_mis, rest_coh)\n",
    "\n",
    "    return string,para "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AriesDataset/Papers/P005.pdf\n",
      "AriesDataset/Papers/P011.pdf\n",
      "AriesDataset/Papers/P039.pdf\n",
      "AriesDataset/Papers/P038.pdf\n",
      "AriesDataset/Papers/P010.pdf\n",
      "AriesDataset/Papers/P004.pdf\n",
      "AriesDataset/Papers/P012.pdf\n",
      "AriesDataset/Papers/P006.pdf\n",
      "AriesDataset/Papers/P007.pdf\n",
      "AriesDataset/Papers/P013.pdf\n",
      "AriesDataset/Papers/P017.pdf\n",
      "AriesDataset/Papers/P003.pdf\n",
      "AriesDataset/Papers/P002.pdf\n",
      "AriesDataset/Papers/P016.pdf\n",
      "AriesDataset/Papers/P028.pdf\n",
      "AriesDataset/Papers/P014.pdf\n",
      "AriesDataset/Papers/P015.pdf\n",
      "AriesDataset/Papers/P001.pdf\n",
      "AriesDataset/Papers/P029.pdf\n",
      "AriesDataset/Papers/P099.pdf\n",
      "AriesDataset/Papers/P066.pdf\n",
      "AriesDataset/Papers/P072.pdf\n",
      "AriesDataset/Papers/P112.pdf\n",
      "AriesDataset/Papers/P106.pdf\n",
      "AriesDataset/Papers/P107.pdf\n",
      "AriesDataset/Papers/P113.pdf\n",
      "AriesDataset/Papers/P073.pdf\n",
      "AriesDataset/Papers/P067.pdf\n",
      "AriesDataset/Papers/P098.pdf\n",
      "AriesDataset/Papers/P071.pdf\n",
      "AriesDataset/Papers/P065.pdf\n",
      "AriesDataset/Papers/P059.pdf\n",
      "AriesDataset/Papers/P105.pdf\n",
      "AriesDataset/Papers/P111.pdf\n",
      "AriesDataset/Papers/P110.pdf\n",
      "AriesDataset/Papers/P104.pdf\n",
      "AriesDataset/Papers/P058.pdf\n",
      "AriesDataset/Papers/P064.pdf\n",
      "AriesDataset/Papers/P070.pdf\n",
      "AriesDataset/Papers/P048.pdf\n",
      "AriesDataset/Papers/P074.pdf\n",
      "AriesDataset/Papers/P060.pdf\n",
      "AriesDataset/Papers/P128.pdf\n",
      "AriesDataset/Papers/P100.pdf\n",
      "AriesDataset/Papers/P114.pdf\n",
      "AriesDataset/Papers/P115.pdf\n",
      "AriesDataset/Papers/P101.pdf\n",
      "AriesDataset/Papers/P129.pdf\n",
      "AriesDataset/Papers/P061.pdf\n",
      "AriesDataset/Papers/P075.pdf\n",
      "AriesDataset/Papers/P049.pdf\n",
      "AriesDataset/Papers/P088.pdf\n",
      "AriesDataset/Papers/P063.pdf\n",
      "AriesDataset/Papers/P077.pdf\n",
      "AriesDataset/Papers/P117.pdf\n",
      "AriesDataset/Papers/P103.pdf\n",
      "AriesDataset/Papers/P102.pdf\n",
      "AriesDataset/Papers/P116.pdf\n",
      "AriesDataset/Papers/P076.pdf\n",
      "AriesDataset/Papers/P062.pdf\n",
      "AriesDataset/Papers/P089.pdf\n",
      "AriesDataset/Papers/P084.pdf\n",
      "AriesDataset/Papers/P090.pdf\n",
      "AriesDataset/Papers/P047.pdf\n",
      "AriesDataset/Papers/P053.pdf\n",
      "AriesDataset/Papers/P133.pdf\n",
      "AriesDataset/Papers/P127.pdf\n",
      "AriesDataset/Papers/P126.pdf\n",
      "AriesDataset/Papers/P132.pdf\n",
      "AriesDataset/Papers/P052.pdf\n",
      "AriesDataset/Papers/P046.pdf\n",
      "AriesDataset/Papers/P091.pdf\n",
      "AriesDataset/Papers/P085.pdf\n",
      "AriesDataset/Papers/P093.pdf\n",
      "AriesDataset/Papers/P087.pdf\n",
      "AriesDataset/Papers/P050.pdf\n",
      "AriesDataset/Papers/P044.pdf\n",
      "AriesDataset/Papers/P078.pdf\n",
      "AriesDataset/Papers/P124.pdf\n",
      "AriesDataset/Papers/P130.pdf\n",
      "AriesDataset/Papers/P118.pdf\n",
      "AriesDataset/Papers/P119.pdf\n",
      "AriesDataset/Papers/P131.pdf\n",
      "AriesDataset/Papers/P125.pdf\n",
      "AriesDataset/Papers/P079.pdf\n",
      "AriesDataset/Papers/P045.pdf\n",
      "AriesDataset/Papers/P051.pdf\n",
      "AriesDataset/Papers/P086.pdf\n",
      "AriesDataset/Papers/P092.pdf\n",
      "AriesDataset/Papers/P096.pdf\n",
      "AriesDataset/Papers/P082.pdf\n",
      "AriesDataset/Papers/P069.pdf\n",
      "AriesDataset/Papers/P055.pdf\n",
      "AriesDataset/Papers/P041.pdf\n",
      "AriesDataset/Papers/P109.pdf\n",
      "AriesDataset/Papers/P121.pdf\n",
      "AriesDataset/Papers/P135.pdf\n",
      "AriesDataset/Papers/P134.pdf\n",
      "AriesDataset/Papers/P120.pdf\n",
      "AriesDataset/Papers/P108.pdf\n",
      "AriesDataset/Papers/P040.pdf\n",
      "AriesDataset/Papers/P054.pdf\n",
      "AriesDataset/Papers/P068.pdf\n",
      "AriesDataset/Papers/P083.pdf\n",
      "AriesDataset/Papers/P097.pdf\n",
      "AriesDataset/Papers/P081.pdf\n",
      "AriesDataset/Papers/P095.pdf\n",
      "AriesDataset/Papers/P042.pdf\n",
      "AriesDataset/Papers/P056.pdf\n",
      "AriesDataset/Papers/P122.pdf\n",
      "AriesDataset/Papers/P123.pdf\n",
      "AriesDataset/Papers/P057.pdf\n",
      "AriesDataset/Papers/P043.pdf\n",
      "AriesDataset/Papers/P094.pdf\n",
      "AriesDataset/Papers/P080.pdf\n",
      "AriesDataset/Papers/P024.pdf\n",
      "AriesDataset/Papers/P030.pdf\n",
      "AriesDataset/Papers/P018.pdf\n",
      "AriesDataset/Papers/P019.pdf\n",
      "AriesDataset/Papers/P031.pdf\n",
      "AriesDataset/Papers/P025.pdf\n",
      "AriesDataset/Papers/P033.pdf\n",
      "AriesDataset/Papers/P027.pdf\n",
      "AriesDataset/Papers/P026.pdf\n",
      "AriesDataset/Papers/P032.pdf\n",
      "AriesDataset/Papers/P036.pdf\n",
      "AriesDataset/Papers/P022.pdf\n",
      "AriesDataset/Papers/P023.pdf\n",
      "AriesDataset/Papers/P037.pdf\n",
      "AriesDataset/Papers/P009.pdf\n",
      "AriesDataset/Papers/P021.pdf\n",
      "AriesDataset/Papers/P035.pdf\n",
      "AriesDataset/Papers/P034.pdf\n",
      "AriesDataset/Papers/P020.pdf\n",
      "AriesDataset/Papers/P008.pdf\n",
      "Saved predictions to prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = []\n",
    "\n",
    "    folder_path = \"AriesDataset/Papers\"\n",
    "    for doc in os.listdir(folder_path):\n",
    "        if doc.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, doc)\n",
    "            status, paragraph = predict(pdf_path)\n",
    "            results.append({\n",
    "                \"Filename\": doc,\n",
    "                \"Status\": status,\n",
    "                \"Paragraph\": paragraph\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"prediction_results.csv\", index=False)\n",
    "    print(\"Saved predictions to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Status</th>\n",
       "      <th>Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P005.pdf</td>\n",
       "      <td>Publishable</td>\n",
       "      <td>This paper is publishable due to its novel and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P011.pdf</td>\n",
       "      <td>Publishable</td>\n",
       "      <td>This paper offers a novel and comprehensive so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P039.pdf</td>\n",
       "      <td>Unpublishable</td>\n",
       "      <td>The paper is unpublishable due to its incohere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P038.pdf</td>\n",
       "      <td>Unpublishable</td>\n",
       "      <td>The paper is unpublishable due to its blend of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P010.pdf</td>\n",
       "      <td>Publishable</td>\n",
       "      <td>This paper introduces MB-CAL, a novel reinforc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename         Status                                          Paragraph\n",
       "0  P005.pdf    Publishable  This paper is publishable due to its novel and...\n",
       "1  P011.pdf    Publishable  This paper offers a novel and comprehensive so...\n",
       "2  P039.pdf  Unpublishable  The paper is unpublishable due to its incohere...\n",
       "3  P038.pdf  Unpublishable  The paper is unpublishable due to its blend of...\n",
       "4  P010.pdf    Publishable  This paper introduces MB-CAL, a novel reinforc..."
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"prediction_results.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace header Filename with Paper ID\n",
    "data.rename(columns={'Filename': 'Paper ID'}, inplace=True)\n",
    "data.rename(columns={'Status': 'Publishable'}, inplace=True)\n",
    "data.rename(columns={'Paragraph': 'Explanation'}, inplace=True)\n",
    "\n",
    "# remove the last 4 characters from Paper ID\n",
    "data['Paper ID'] = data['Paper ID'].str[:-4]\n",
    "\n",
    "# map Publishable to 1 and Unpublishable to 0\n",
    "data['Publishable'] = data['Publishable'].map({'Publishable': 1, 'Unpublishable': 0})\n",
    "data.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
